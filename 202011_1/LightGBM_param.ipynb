{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "x_b_train = pd.read_csv('data_b_train.csv')\n",
    "x_b_test = pd.read_csv('data_b_test.csv')\n",
    "x_m_train = pd.read_csv('data_m_train.csv')\n",
    "x_m_test = pd.read_csv('data_m_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "\n",
    "\n",
    "# b表使用特征\n",
    "b_col = ['id', 'x_num_0', 'x_num_1', 'x_num_2', 'x_num_3', 'x_cat_0', 'x_cat_1',\n",
    "           'x_cat_2', 'x_cat_3', 'x_cat_4', 'x_cat_9', 'x_cat_10', 'x_cat_11']\n",
    "\n",
    "x_b_train = x_b_train[b_col]\n",
    "x_b_test = x_b_test[b_col]\n",
    "\n",
    "\n",
    "m_col = ['id','x_num_70', 'x_num_5', 'x_num_6', 'x_num_7', 'x_num_10',\n",
    "         'x_num_13', 'x_num_14', 'x_num_15', 'x_num_17', 'x_num_18', 'x_num_20',\n",
    "         'x_num_22', 'x_num_23', 'x_num_24', 'x_num_25', 'x_num_26', 'x_num_27',\n",
    "         'x_num_28', 'x_num_30','x_num_32', 'x_num_33',\n",
    "         'x_num_39', 'x_num_41', 'x_num_43', 'x_num_45', 'x_num_46',\n",
    "         'x_num_47', 'x_num_49', 'x_num_50', 'x_num_51', 'x_num_55', \n",
    "         'x_num_63', 'x_num_68', 'x_num_69']\n",
    "\n",
    "# x_m_train = x_m_train[m_col]\n",
    "# x_m_test = x_m_test[m_col]\n",
    "\n",
    "\n",
    "x_m_test.replace(-99.0, np.nan, inplace=True)\n",
    "x_b_test.replace(-99,0,inplace=True)\n",
    "\n",
    "m_cols = [ 'x_num_70', 'x_num_5', 'x_num_6', 'x_num_7', 'x_num_10',\n",
    "          'x_num_14', 'x_num_15', 'x_num_17', 'x_num_18', 'x_num_20',\n",
    "          'x_num_22', 'x_num_24', 'x_num_25', 'x_num_26', 'x_num_27',\n",
    "          'x_num_28', 'x_num_30','x_num_32', 'x_num_33','x_num_41', 'x_num_43', \n",
    "          'x_num_45', 'x_num_46','x_num_49', 'x_num_50','x_num_55', \n",
    "           'x_num_63', 'x_num_68', 'x_num_69']\n",
    "\n",
    "\n",
    "\n",
    "# 选取相同id下最大的timestamp,最大值，标准差，离散系数\n",
    "\n",
    "def changeName(df, name):\n",
    "    new = []\n",
    "    for col in df.columns.values:\n",
    "        if col is 'id':\n",
    "            new.append(col)\n",
    "        else:\n",
    "            new.append(col+'_'+name)\n",
    "    return new\n",
    "    \n",
    "\n",
    "\n",
    "x_m_train_mean = x_m_train[m_col].groupby('id', as_index=False).mean()\n",
    "x_m_train_time = x_m_train[m_col+['timestamp']].sort_values('timestamp', ascending=False).groupby('id', as_index=False).first()\n",
    "x_m_train_time.drop('timestamp', axis=1, inplace=True)\n",
    "x_m_train_max = x_m_train[m_col].groupby('id', as_index=False).max()\n",
    "x_m_train_std = x_m_train[m_col].groupby('id', as_index=False).std()\n",
    "x_m_train_cov = x_m_train_std / x_m_train_mean\n",
    "x_m_train_median = x_m_train[m_col].groupby('id', as_index=False).median()\n",
    "\n",
    "\n",
    "# time/max\n",
    "# x_m_train_div = x_m_train_time / x_m_train_max\n",
    "\n",
    "\n",
    "# # 计算差值的std\n",
    "# x_m_train_diff = x_m_train[m_col].groupby('id', as_index=False).diff()\n",
    "# x_m_train_diff['id'] = x_m_train['id']\n",
    "# x_m_train_diff_min = x_m_train_diff.groupby('id', as_index=False).min()\n",
    "# x_m_train_diff_std = x_m_train_diff.groupby('id', as_index=False).std()\n",
    "\n",
    "\n",
    "\n",
    "x_m_train_time.columns = changeName(x_m_train_time, 'time')\n",
    "x_m_train_max.columns = changeName(x_m_train_max, 'max')\n",
    "x_m_train_std.columns = changeName(x_m_train_std, 'std')\n",
    "x_m_train_std['id']=x_m_train_max['id']\n",
    "x_m_train_cov.columns = changeName(x_m_train_cov, 'cov')\n",
    "x_m_train_cov['id']=x_m_train_max['id']\n",
    "x_m_train_median.columns = changeName(x_m_train_median, 'median')\n",
    "# x_m_train_diff_std.columns = changeName(x_m_train_diff_std, 'diff_std')\n",
    "\n",
    "# x_m_train_div.columns = changeName(x_m_train_div, 'div')\n",
    "# x_m_train_div['id']=x_m_train_max['id']\n",
    "\n",
    "    \n",
    "x_m_train = pd.merge(x_m_train_time, x_m_train_max, how='left',on='id')\n",
    "x_m_train = pd.merge(x_m_train, x_m_train_std, how='left',on='id')\n",
    "x_m_train = pd.merge(x_m_train, x_m_train_cov, how='left',on='id')\n",
    "x_m_train = pd.merge(x_m_train, x_m_train_median, how='left',on='id')\n",
    "\n",
    "\n",
    "\n",
    "x_m_test_mean = x_m_test[m_col].groupby('id', as_index=False).mean()\n",
    "x_m_test_time = x_m_test[m_col+['timestamp']].sort_values('timestamp', ascending=False).groupby('id', as_index=False).first()\n",
    "x_m_test_time.drop('timestamp', axis=1, inplace=True)\n",
    "x_m_test_max = x_m_test[m_col].groupby('id', as_index=False).max()\n",
    "x_m_test_std = x_m_test[m_col].groupby('id', as_index=False).std()\n",
    "x_m_test_cov = x_m_test_std / x_m_test_mean\n",
    "x_m_test_median = x_m_test[m_col].groupby('id', as_index=False).median()\n",
    "\n",
    "\n",
    "# time/max\n",
    "# x_m_test_div = x_m_test_time / x_m_test_max\n",
    "# # 计算差值的std\n",
    "# x_m_test_diff = x_m_test[m_col].groupby('id', as_index=False).diff()\n",
    "# x_m_test_diff['id'] = x_m_test['id']\n",
    "# x_m_test_diff_min = x_m_test_diff.groupby('id', as_index=False).min()\n",
    "# x_m_test_diff_std = x_m_test_diff.groupby('id', as_index=False).std()\n",
    "# x_m_train_diff_std['id'] = x_m_train_max['id']\n",
    "\n",
    "\n",
    "x_m_test_time.columns = changeName(x_m_test_time, 'time')\n",
    "x_m_test_max.columns = changeName(x_m_test_max, 'max')\n",
    "x_m_test_std.columns = changeName(x_m_test_std, 'std')\n",
    "x_m_test_std['id']=x_m_test_max['id']\n",
    "x_m_test_cov.columns = changeName(x_m_test_cov, 'cov')\n",
    "x_m_test_cov['id']=x_m_test_max['id']\n",
    "x_m_test_median.columns = changeName(x_m_test_median, 'median')\n",
    "# x_m_test_diff_std.columns = changeName(x_m_test_diff_std, 'diff_std')\n",
    "\n",
    "# x_m_test_div.columns = changeName(x_m_test_div, 'div')\n",
    "# x_m_test_div['id']=x_m_test_max['id']\n",
    "\n",
    "\n",
    "    \n",
    "x_m_test = pd.merge(x_m_test_time, x_m_test_max, how='left',on='id')  \n",
    "x_m_test = pd.merge(x_m_test, x_m_test_std, how='left',on='id')\n",
    "x_m_test = pd.merge(x_m_test, x_m_test_cov, how='left',on='id')\n",
    "x_m_test = pd.merge(x_m_test, x_m_test_median, how='left',on='id')\n",
    "\n",
    "\n",
    "# 将b表与m表拼接\n",
    "train = pd.merge(x_b_train, x_m_train, how='left',on='id')\n",
    "test = pd.merge(x_b_test, x_m_test, how='left',on='id')\n",
    "\n",
    "\n",
    "y_train = y_train['target']\n",
    "\n",
    "x_train = train.drop('id', axis=1)\n",
    "x_test = test.drop('id', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# # 构建模型\n",
    "# train_data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "# params = {'boosting':'gbdt',\n",
    "#           'objective':'binary',\n",
    "#           'max_depth':6,\n",
    "#           'learning_rate':0.01,\n",
    "#           'num_leaves':50,\n",
    "#           'metric': ['binary_logloss', 'auc']\n",
    "#          }\n",
    "\n",
    "\n",
    "# my_model = lgb.train(params, train_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's auc: 0.852781 + 0.00480528\tcv_agg's binary_logloss: 0.249676 + 0.0119209\n",
      "[100]\tcv_agg's auc: 0.851758 + 0.00449059\tcv_agg's binary_logloss: 0.252858 + 0.0119128\n",
      "best n_estimators: 52 52\n",
      "best cv score: 0.8530912982651735 0.24948749057736727\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#              'objective':'binary',\n",
    "#              'is_unbalance': True,\n",
    "#              'metric': 'binary_logloss,auc',\n",
    "#              'max_depth':6,\n",
    "#              'num_leaves':150,\n",
    "#              'learning_rate':0.1,\n",
    "#             'feature_fraction':0.7,\n",
    "#              'min_child_samples':21,\n",
    "#              'min_child_weight':0.001,\n",
    "#              'bagging_fraction' :1,\n",
    "#              'bagging_freq':2,\n",
    "#              'reg_alpha':0.001,\n",
    "#              'reg_lambda':8,\n",
    "#              'cat_smooth': 0,\n",
    "  \n",
    "#     }\n",
    "\n",
    "params = {'boosting':'gbdt',\n",
    "          'objective':'binary',\n",
    "          'max_depth':6,\n",
    "          'learning_rate':0.1,\n",
    "          'num_leaves':50,\n",
    "          'metric':['auc', 'binary_logloss']\n",
    "         }\n",
    "\n",
    "data_train = lgb.Dataset(x_train, y_train, silent=True)\n",
    "cv_results = lgb.cv(\n",
    "    params, lgb.Dataset(x_train, y_train, silent=True), \n",
    "    num_boost_round=5000, nfold=5, stratified=False, shuffle=True, metrics=['auc', 'binary_logloss'],\n",
    "    early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\n",
    "\n",
    "print('best n_estimators:', len(cv_results['auc-mean']), len(cv_results['binary_logloss-mean']))\n",
    "print('best cv score:', cv_results['auc-mean'][-1], cv_results['binary_logloss-mean'][-1])\n",
    "\n",
    "# best n_estimators: 526 526\n",
    "# best cv score: 0.834260740650152 0.258253590504551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 65 candidates, totalling 325 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 325 out of 325 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'num_leaves': 40}, 0.8548492088809312)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找最优参数'max_depth'，  'num_leaves'\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params_test1 = {\n",
    "              'max_depth': range(3, 8, 1),\n",
    "              'num_leaves':range(20, 150, 10),\n",
    "             }\n",
    "\n",
    "# model_lgb = LGBMClassifier(\n",
    "#                         objective = 'binary',\n",
    "#                          is_unbalance = True,\n",
    "#                          metric = 'binary_logloss,auc',\n",
    "#                          max_depth = 6,\n",
    "#                          num_leaves = 40,\n",
    "#                          learning_rate = 0.1,\n",
    "#                          feature_fraction = 0.7,\n",
    "#                          min_child_samples=21,\n",
    "#                          min_child_weight=0.001,\n",
    "#                          bagging_fraction = 1,\n",
    "#                          bagging_freq = 2,\n",
    "#                          reg_alpha = 0.001,\n",
    "#                          reg_lambda = 8,\n",
    "#                          cat_smooth = 0,\n",
    "#                          num_iterations = 1000)\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting='gbdt',\n",
    "          objective='binary',\n",
    "          max_depth=6,\n",
    "          learning_rate=0.1,\n",
    "          max_bin=200,\n",
    "          num_leaves=50,\n",
    "          metric=['auc', 'binary_logloss'],\n",
    "                         )\n",
    "\n",
    "\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=1, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "# 50迭代\n",
    "# LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
    "#                colsample_bytree=0.8, importance_type='split', learning_rate=0.1,\n",
    "#                max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
    "#                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=50,\n",
    "#                objective='binary', random_state=None, reg_alpha=0.0,\n",
    "#                reg_lambda=0.0, silent=True, subsample=0.8,\n",
    "#                subsample_for_bin=200000, subsample_freq=0)\n",
    "# 0.8048743175850636\n",
    "\n",
    "\n",
    "# 2103迭代 25min\n",
    "# ({'max_depth': 4, 'num_leaves': 50}, 0.7558331524967551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   32.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 31}, 0.8520292278361599)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找最优参数'max_depth'，  'num_leaves'\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params_test1 = {\n",
    "              'num_leaves': range(30,50,1)\n",
    "             }\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=40, max_depth=5, \n",
    "       learning_rate=0.1, n_estimators=52)\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=2, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "# ({'max_depth': 9, 'num_leaves': 120}, 0.8171362874665284)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_child_samples': 12, 'min_child_weight': 0.001}, 0.8518072974394683)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找最优参数min_data_in_leaf 和 min_sum_hessian_in_leaf\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params_test1={\n",
    "    'min_child_samples': [8, 9, 10, 11, 12],\n",
    "    'min_child_weight':[0.001, 0.002]\n",
    "}\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=31, max_depth=5, \n",
    "       learning_rate=0.1, n_estimators=52)\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=1, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "# ({'min_child_samples': 19, 'min_child_weight': 0.001}, 0.816678716420489)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=4)]: Done 125 out of 125 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bagging_fraction': 0.6, 'feature_fraction': 0.5}, 0.8542423642508912)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找最优参数 feature_fraction 和 bagging_fraction\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params_test1={\n",
    "    'feature_fraction': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=31, max_depth=5, \n",
    "       learning_rate=0.1, n_estimators=52,\n",
    "                           min_child_samples=12,min_child_weight=0.001)\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=1, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "# ({'bagging_fraction': 0.6, 'feature_fraction': 0.5}, 0.8185608706918892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed:   43.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.5, 'reg_lambda': 0.5}, 0.835574640173394)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找最优正则化参数\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params_test1={\n",
    "    'reg_alpha': [0, 0.08, 0.3, 0.5],\n",
    "    'reg_lambda': [0, 0.08, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=50, max_depth=6, \n",
    "       class_weight='balanced',learning_rate=0.01, n_estimators=500, min_data_in_leaf=10, max_bin=200,\n",
    "                           min_child_samples=8,min_child_weight=0.001,\n",
    "                          bagging_fraction=0.6, feature_fraction=0.7)\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=1, n_jobs=2, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "# ({'reg_alpha': 0, 'reg_lambda': 0.3}, 0.8201618208516888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'cat_smooth': 0}, 0.835574640173394)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_test1={\n",
    "   'cat_smooth': [0,10,20],\n",
    "}\n",
    "\n",
    "model_lgb = LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=50, max_depth=6, \n",
    "       class_weight='balanced',learning_rate=0.01, n_estimators=500, min_data_in_leaf=10, max_bin=200,\n",
    "                           min_child_samples=8,min_child_weight=0.001,\n",
    "                          bagging_fraction=0.6, feature_fraction=0.7,\n",
    "                          reg_alpha=0.5, reg_lambda= 0.5)\n",
    "# 创建网格\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, cv = 5, verbose=1, n_jobs=2, scoring= 'roc_auc')\n",
    "\n",
    "#训练\n",
    "#打印最优的分类参数\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "# ({'reg_alpha': 0, 'reg_lambda': 0.3}, 0.8201618208516888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's auc: 0.827779 + 0.00959428\tcv_agg's binary_logloss: 0.293895 + 0.00858494\n",
      "[100]\tcv_agg's auc: 0.830379 + 0.00727895\tcv_agg's binary_logloss: 0.27655 + 0.00858205\n",
      "[150]\tcv_agg's auc: 0.832989 + 0.00778029\tcv_agg's binary_logloss: 0.267693 + 0.00883868\n",
      "[200]\tcv_agg's auc: 0.834474 + 0.00674148\tcv_agg's binary_logloss: 0.262646 + 0.00866591\n",
      "[250]\tcv_agg's auc: 0.835437 + 0.00669463\tcv_agg's binary_logloss: 0.259918 + 0.00872479\n",
      "[300]\tcv_agg's auc: 0.836423 + 0.00694939\tcv_agg's binary_logloss: 0.258202 + 0.00896507\n",
      "[350]\tcv_agg's auc: 0.836869 + 0.00720624\tcv_agg's binary_logloss: 0.257276 + 0.00917744\n",
      "[400]\tcv_agg's auc: 0.837424 + 0.00726049\tcv_agg's binary_logloss: 0.256635 + 0.009459\n",
      "[450]\tcv_agg's auc: 0.837672 + 0.0072056\tcv_agg's binary_logloss: 0.256288 + 0.00963297\n",
      "[500]\tcv_agg's auc: 0.837777 + 0.00736242\tcv_agg's binary_logloss: 0.256207 + 0.00982969\n",
      "[550]\tcv_agg's auc: 0.837849 + 0.00760028\tcv_agg's binary_logloss: 0.256144 + 0.0100755\n",
      "[600]\tcv_agg's auc: 0.837891 + 0.0078456\tcv_agg's binary_logloss: 0.256103 + 0.010235\n",
      "[650]\tcv_agg's auc: 0.838006 + 0.00813048\tcv_agg's binary_logloss: 0.256103 + 0.0104497\n",
      "best n_estimators: 641 641\n",
      "best cv score: 0.8380771409391847 0.2560574881733961\n"
     ]
    }
   ],
   "source": [
    "params = {'boosting':'gbdt',\n",
    "          'objective':'binary',\n",
    "          'max_depth':6,\n",
    "          'learning_rate':.01,\n",
    "          'max_bin':200,\n",
    "          'num_leaves':150,\n",
    "          'min_data_in_leaf': 10,\n",
    "          'class_weight':'balanced',\n",
    "          'metric':['auc', 'binary_logloss'],\n",
    "          'in_data_in_leaf':10, \n",
    "          'max_bin':200,\n",
    "        'min_child_samples':8,\n",
    "          'min_child_weight':0.001,\n",
    "          'bagging_fraction':0.6, \n",
    "          'feature_fraction':0.7,\n",
    "          'reg_alpha':0.5,\n",
    "          'reg_lambda':0.5,\n",
    "          'cat_smooth': 0\n",
    "         }\n",
    "\n",
    "data_train = lgb.Dataset(x_train, y_train, silent=True)\n",
    "cv_results = lgb.cv(\n",
    "    params, lgb.Dataset(x_train, y_train, silent=True), \n",
    "    num_boost_round=5000, nfold=5, stratified=False, shuffle=True, metrics=['auc', 'binary_logloss'],\n",
    "    early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\n",
    "\n",
    "print('best n_estimators:', len(cv_results['auc-mean']), len(cv_results['binary_logloss-mean']))\n",
    "print('best cv score:', cv_results['auc-mean'][-1], cv_results['binary_logloss-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
